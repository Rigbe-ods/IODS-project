data("Boston")
library(MASS)
data("Boston")
summary(Boston)
library(dplyr)
library(corrplot)
install.packages("corrplot")
library(dplyr)
library(corrplot)
cor_matrix<-cor(Boston)
cor_matrix <- cor_matrix %>% round(digits=2)
cor_matrix
# plot the correlation matrix
corrplot(cor_matrix, method="circle",type="upper",tl.pos = "d",tl.cex = 0.8)
boston_scaled$crim
# mean scaling
boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
# scaled data(boston_scaled) is a matrix so we are changin to a data frame
boston_scaled <- as.data.frame(boston_scaled)
boston_scaled$crim
# create the quantile bins
bins <- quantile(boston_scaled$crim)
bins
# assign names to the bins and cut the data based on those bins which are the quantiles
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE,labels=c("low","med_low","med_high","high"))
#  remove the original crime data and replace it with the one we just created
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
crime
# we obtain the number of rows to use for sampling
n <- nrow(boston_scaled)
# sample 80 percent of the data, i.e. you have the row indices here
ind <- sample(n,  size = n * 0.8)
# based on those indices we choose our training set
train <- boston_scaled[ind,]
# the rest is the test data
test <- boston_scaled[-ind,]
# we know the correct classes from our test set
correct_classes <- test$crime
# remove the crime classes, so that we replace them with the predicted values from the next steps
test <- dplyr::select(test, -crime)
# lda
lda.fit <- lda(crime ~ . , data = train)
lda.fit
# plot the lda results
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col = classes,pch=classes)
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
library(ggplot2)
data('Boston')
boston_scaled <- scale(Boston)
# euclidean distance matrix
dist_eu <- dist(boston_scaled)
summary(dist_eu)
# k-means clustering
km <-kmeans(boston_scaled, centers = 3)
pairs(Boston[6:10], col = km$cluster)
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled, k)$tot.withinss})
# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')
# k-means clustering
km2 <-kmeans(boston_scaled, centers = 2)
pairs(Boston[2:10], col = km2$cluster)
library(ggplot2)
data('Boston')
boston_scaled <- scale(Boston)
# euclidean distance matrix
dist_eu <- dist(boston_scaled)
summary(dist_eu)
# k-means clustering
km <-kmeans(boston_scaled, centers = 3)
pairs(Boston[6:10], col = km$cluster)
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled, k)$tot.withinss})
# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')
# k-means clustering
km2 <-kmeans(boston_scaled, centers = 2)
pairs(Boston[2:20], col = km2$cluster)
library(ggplot2)
data('Boston')
boston_scaled <- scale(Boston)
# euclidean distance matrix
dist_eu <- dist(boston_scaled)
summary(dist_eu)
# k-means clustering
km <-kmeans(boston_scaled, centers = 3)
pairs(Boston[6:10], col = km$cluster)
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled, k)$tot.withinss})
# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')
# k-means clustering
km2 <-kmeans(boston_scaled, centers = 2)
pairs(Boston[2:5], col = km2$cluster)
library(dplyr)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
# Explore the datasets
str(hd)
dim(hd)
str(gii)
dim(gii)
# Both hd and gii datasets have 195 obs, and 8 and 10 vars respectively.
# Summary of the datasets
summary(hd)
summary(gii)
colnames(hd) <- c("HdiR","Country","Hdi","LifeExp","EduExp","EduMean","Gni","GniMinusHdiR")
colnames(gii) <- c("GiiR","Country","Gii","MaMortalityR","AdBirthRate","ParPer","FemaleSecEdu","MaleSecEdu","FemaleLabor","MaleLabor")
gii <- mutate(gii, FemMaleEdu = FemaleSecEdu / MaleSecEdu)
gii <- mutate(gii, FemMaleLabor = FemaleLabor / MaleLabor)
human <- inner_join(hd, gii, by = "Country", suffix=c(".hd",".gii"))
str(human)
head(human)
write.table(human,file="data/human.txt",sep="\t")
setwd("~/GitHub/IODS-project")
write.table(human,file="data/human.txt",sep="\t")
set.seed(80)
# k-means clustering
km2 <-kmeans(boston_scaled, centers = 3,iter.max=20)
boston_scaled <- data.frame(boston_scaled, cluster=km2$cluster)
# linear discriminant analysis
ldaWithKm <- lda(cluster ~ . , data = boston_scaled)
ldaWithKm
# the function for lda biplot arrows: function copied from datacamp exercise
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(ldaWithKm, dimen = 2,col = boston_scaled$cluster)
lda.arrows(ldaWithKm, myscale = 3)
set.seed(80)
# k-means clustering
km2 <-kmeans(boston_scaled, centers = 3,iter.max=20)
boston_scaled <- data.frame(boston_scaled, cluster=km2$cluster)
# linear discriminant analysis
ldaWithKm <- lda(cluster ~ . , data = boston_scaled)
boston_scaled <- scale(Boston)
set.seed(80)
# k-means clustering
km2 <-kmeans(boston_scaled, centers = 3,iter.max=20)
boston_scaled <- data.frame(boston_scaled, cluster=km2$cluster)
# linear discriminant analysis
ldaWithKm <- lda(cluster ~ . , data = boston_scaled)
ldaWithKm
# the function for lda biplot arrows: function copied from datacamp exercise
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(ldaWithKm, dimen = 2,col = boston_scaled$cluster)
lda.arrows(ldaWithKm, myscale = 3)
